---
published: false
---
The backend, this is where the magic happens; all the processes, from decoding the image to sending the results out, all of this is done by this backend. The backend is straight forward, it accepts the base64 encoded image and sends it to the predictor class which does all the work. What really goes on in the predictor class is what this blog is about and with a little bit of computer vision (CNN only). 

## The Predictor Class:
This is the brain of the webapp, it does everything for me. The process of writing this class was pretty smooth,because I like python, and I enjoyed the whole process of learning this new stuff 'Flask'. I love flask so much, it's so simple yet so powerful, it is so easy to throw together a running local host on this stuff so fast that it took me more time to restart my laptop when the server crashed then it was for me to throw together the initial 'hello world' on flask. The documentation for flask is super helpful, I would highly suggest flask to anyone trying to make a simple webapp without having to learn intimidating libraries. The predictor model of the predictor class ( Canvas class in the repo located under <a href='' target='_blank'>webapp/HWES/canvas_process.py</a>) is built with the help of fastai. Fastai provides high-level api for quickly creating deep learning model. I adore pytorch, what more can a person want than the dynamic computational graphs of pytorch, but the transfer learning part always seemed a little off to me. I was never successful at getting it to work, they were good but building the model from scratch gave me better results. Then I found out about <a href='https://fast.ai' target='_blank'>fastai</a>, the high level and mid level api of fastai with it's ability to seamlessly integrate any other stuff written in pytorch is just magical. So yeah, then I trained my model on dataset provided on kaggle by <a href='https://www.kaggle.com/xainano/handwrittenmathsymbols' target='_blank'>Xainano</a>. I used resnet50 architecture here, this is a bit of an overkill but I wanted to be on the safe side, pretrained on imagenet dataset. I didn't transform the data that much other than random rotate with max angle of 20Â°. The reason I didn't many transformations is that at the end the model will be predicting from a stable image i.e the image to be predicted will just be black text with a white background. The learning rate was found using <a href='https://docs.fast.ai/callback.schedule.html#Learner.lr_find' target='_blank'> `lr_find()`, first introduced by Leslie N. Smith in his paper <a href='https://arxiv.org/pdf/1506.01186.pdf' target='_blank'> Cyclical Learning Rates for Training Neural Networks</a>, which improved the loss significantly. There are some other minor things as well but they aren't worth mentioning. I am really happy with the prediction of the model, it isn't 100% accurate but with minimal training I cannot ask for more.
  
## The Maths Class:
This class is pretty straightforward it just does maths, nothing more. The hardest part was integrating the integration part (pun not intended), converting the user sent string into mathematical equations. For integration I had to first change the string to LaTeX format (I am not entirely sure if it is LaTeX or not) and then perform the operations; performing simple maths was easy I just had to send the maths to <a href='https://docs.python.org/3/library/functions.html#eval' target='_blank'> `eval()`. However, working with `eval` is very not recommemded as it performs anything the user enters so if the user enters `__import__('os').system(rm -rf *)` your project is gone. In this use case it is fine, as the user can only input inside the canvas which cannot identify alphabets. I am happy with how the class works, also the maths class can be found under webapp/HWES/utils/)